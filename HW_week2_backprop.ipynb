{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG6Ee3KS79w8"
      },
      "source": [
        "Deadline: 15.02.2022 23:59"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScBmMfiT79w-"
      },
      "source": [
        "# Домашние задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kJDrhqV79w-"
      },
      "source": [
        "1. Добавить Bias и посчитать для них градиенты.\n",
        "2. Сравнить градинеты с тем, как считает PyTorch AutoGrad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 479,
      "metadata": {
        "id": "RrSbkFzA79w_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "input_size = 3\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "MpXiHMgqjXdd"
      },
      "execution_count": 480,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create random input and output data\n",
        "torch.manual_seed(42)\n",
        "\n",
        "x = torch.randn(batch_size, input_size, device=device, dtype=dtype, requires_grad=True)\n",
        "y = torch.randn(batch_size, output_size, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(input_size, hidden_size, device=device, dtype=dtype, requires_grad=True)\n",
        "w2 = torch.randn(hidden_size, output_size, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "# Randomly initialize bias\n",
        "b1 = torch.randn(1, hidden_size, device=device, dtype=dtype, requires_grad=True)\n",
        "b2 = torch.randn(1, output_size, device=device, dtype=dtype, requires_grad=True)\n"
      ],
      "metadata": {
        "id": "ji69E-BuxSbH"
      },
      "execution_count": 481,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Градиент ручками\n",
        "h1 = torch.mm(x, w1) + b1\n",
        "h1_relu = h1.clamp(min=0.)\n",
        "y_pred = torch.mm(h1_relu, w2) + b2\n",
        "\n",
        "loss = (y_pred - y).pow(2).sum()#.item()\n",
        "\n",
        "with torch.no_grad():\n",
        "    s = 2*(y_pred - y)\n",
        "    h_grad = torch.mm(s, w2.T)\n",
        "    h_grad[h1_relu==0] = 0\n",
        "\n",
        "    grad_w2 = torch.mm(h1_relu.T, s)\n",
        "    grad_b2 = torch.sum(s, axis=0)\n",
        "\n",
        "    grad_w1 = torch.mm(x.T, h_grad)\n",
        "    grad_b1 = torch.sum(h_grad, axis=0)"
      ],
      "metadata": {
        "id": "DmigT_OJVWm5"
      },
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_b1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPDoDLUqdvCu",
        "outputId": "aa38ae01-9f65-4585-a82b-fefd170a995a"
      },
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([34.4378, 89.7073])"
            ]
          },
          "metadata": {},
          "execution_count": 483
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Градиент ножками\n",
        "\n",
        "loss.backward()\n",
        "autograd_b1 = b1.grad\n",
        "autograd_b2 = b2.grad\n",
        "\n",
        "autograd_w1 = w1.grad\n",
        "autograd_w2 = w2.grad"
      ],
      "metadata": {
        "id": "YNZpZ0UctuEt"
      },
      "execution_count": 484,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udhsIOfwyfO5",
        "outputId": "653f87f2-9c26-49eb-f43f-197ce38ce400"
      },
      "execution_count": 485,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-15.0927,  -9.1019],\n",
              "        [ 45.8589, -99.3424],\n",
              "        [-38.4661,   4.6612]])"
            ]
          },
          "metadata": {},
          "execution_count": 485
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autograd_w1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkcAX_VIzjMq",
        "outputId": "7de83835-80df-42a4-d391-2bc9dad8f75e"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-15.0927,  -9.1019],\n",
              "        [ 45.8589, -99.3424],\n",
              "        [-38.4661,   4.6612]])"
            ]
          },
          "metadata": {},
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Проверим равны ли ручные градиенты - пайторчовским"
      ],
      "metadata": {
        "id": "N6YYwS7DoJFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert (grad_w1 == autograd_w1).all()\n",
        "assert (grad_w2 == autograd_w2).all()\n",
        "assert (grad_b1 == autograd_b1).all()\n",
        "assert (grad_b2 == autograd_b2).all()"
      ],
      "metadata": {
        "id": "sLYjYKG-z6tP"
      },
      "execution_count": 487,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "X = torch.randn(128, batch_size, input_size, device=device, dtype=dtype, requires_grad=True)\n",
        "Y = torch.randn(128, batch_size, output_size, device=device, dtype=dtype, requires_grad=True)"
      ],
      "metadata": {
        "id": "-ajCzULkYXPy"
      },
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1_c = w1.clone().detach()\n",
        "w2_c = w2.clone().detach()\n",
        "b2_c = b2.clone().detach()\n",
        "b1_c = b1.clone().detach()"
      ],
      "metadata": {
        "id": "mjd3vgJybkjx"
      },
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG7Wtx6XgsIe",
        "outputId": "8e05f4da-e139-47a2-f7dc-0b1a140af6cf"
      },
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.7379,  0.1841]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 490
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Запущу фиктивное обучение и буду выводить лосс, чтобы понять одинаково ли работает автоматический градиент торча и посчитанный руками"
      ],
      "metadata": {
        "id": "Zl3QahHxoYQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-6\n",
        "k = 0\n",
        "\n",
        "for x,y in zip(X,Y):\n",
        "    h1 = torch.mm(x, w1) + b1\n",
        "    h1_relu = h1.clamp(min=0.)\n",
        "    y_pred = torch.mm(h1_relu, w2) + b2\n",
        "    k += 1\n",
        "    loss = loss = (y_pred - y).pow(2).sum()#loss_fn(y_pred, y)\n",
        "    if k % 10 == 0:\n",
        "        print(k, loss.item())\n",
        "    \n",
        "    loss.backward()\n",
        "   \n",
        "    with torch.no_grad():\n",
        "      \n",
        "        w1 -= learning_rate * w1.grad\n",
        "        w2 -= learning_rate * w2.grad\n",
        "        b1 -= learning_rate * b1.grad\n",
        "        b2 -= learning_rate * b2.grad\n",
        "\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()\n",
        "        b1.grad.zero_()\n",
        "        b2.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVOQlfnpvHk6",
        "outputId": "3a800f83-09fa-4b77-e486-d70860a91c2b"
      },
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 205.3661346435547\n",
            "20 204.7293701171875\n",
            "30 286.1779479980469\n",
            "40 226.7199249267578\n",
            "50 251.77049255371094\n",
            "60 195.32078552246094\n",
            "70 164.57962036132812\n",
            "80 186.96812438964844\n",
            "90 166.11111450195312\n",
            "100 184.751953125\n",
            "110 197.72454833984375\n",
            "120 222.17405700683594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# закостылю, чтобы не переписывать названия\n",
        "w1, w2 = w1_c, w2_c\n",
        "b1, b2 = b1_c, b2_c\n",
        "k = 0 \n",
        "with torch.no_grad():\n",
        "  learning_rate = 1e-6\n",
        "  for x,y in zip(X,Y):\n",
        "      # Forward pass: compute predicted y\n",
        "      h1 = torch.mm(x, w1) + b1\n",
        "      h1_relu = h1.clamp(min=0.)\n",
        "      y_pred = torch.mm(h1_relu, w2) + b2\n",
        "      # Compute and print loss\n",
        "      loss = (y_pred - y).pow(2).sum().item()\n",
        "      k += 1\n",
        "      if k % 10 == 0:\n",
        "        print(k, loss)\n",
        "\n",
        "      s = 2*(y_pred - y)\n",
        "      h_grad = torch.mm(s, w2.T)\n",
        "      h_grad[h1_relu==0] = 0\n",
        "\n",
        "      grad_w2 = torch.mm(h1_relu.T, s)\n",
        "      grad_b2 = torch.sum(s, axis=0)\n",
        "\n",
        "      grad_w1 = torch.mm(x.T, h_grad)\n",
        "      grad_b1 = torch.sum(h_grad, axis=0)\n",
        "\n",
        "      # Update weights using gradient descent\n",
        "      \n",
        "      w1 -= learning_rate * grad_w1\n",
        "      w2 -= learning_rate * grad_w2\n",
        "      b1 -= learning_rate * grad_b1\n",
        "      b2 -= learning_rate * grad_b2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNoDiU4HWTXI",
        "outputId": "a07f6882-4509-479f-fc5c-39404a8d11a5"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 205.43722534179688\n",
            "20 204.7981414794922\n",
            "30 286.26251220703125\n",
            "40 226.7998504638672\n",
            "50 251.86378479003906\n",
            "60 195.39694213867188\n",
            "70 164.6399688720703\n",
            "80 187.0312042236328\n",
            "90 166.1663055419922\n",
            "100 184.79202270507812\n",
            "110 197.80043029785156\n",
            "120 222.251708984375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Вывод: Лосс одинаковый - градиент считается правильно"
      ],
      "metadata": {
        "id": "ODr5QGPJoroF"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "HW_week2_backprop.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}